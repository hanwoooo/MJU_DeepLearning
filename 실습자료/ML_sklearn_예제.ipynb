{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKWTBirPuqWl",
        "outputId": "deb7353e-21a7-4d4e-9e11-b51a9dc77036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Linear Regression (회귀) ===\n",
            "Accuracy: 0.956\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       0.88      1.00      0.94        15\n",
            "   virginica       1.00      0.87      0.93        15\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.96      0.96        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n",
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.933\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       0.88      0.93      0.90        15\n",
            "   virginica       0.93      0.87      0.90        15\n",
            "\n",
            "    accuracy                           0.93        45\n",
            "   macro avg       0.93      0.93      0.93        45\n",
            "weighted avg       0.93      0.93      0.93        45\n",
            "\n",
            "\n",
            "=== SVM ===\n",
            "Accuracy: 1.000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       1.00      1.00      1.00        15\n",
            "   virginica       1.00      1.00      1.00        15\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n",
            "\n",
            "=== Decision Tree ===\n",
            "Accuracy: 0.933\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       1.00      0.80      0.89        15\n",
            "   virginica       0.83      1.00      0.91        15\n",
            "\n",
            "    accuracy                           0.93        45\n",
            "   macro avg       0.94      0.93      0.93        45\n",
            "weighted avg       0.94      0.93      0.93        45\n",
            "\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 0.889\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       0.78      0.93      0.85        15\n",
            "   virginica       0.92      0.73      0.81        15\n",
            "\n",
            "    accuracy                           0.89        45\n",
            "   macro avg       0.90      0.89      0.89        45\n",
            "weighted avg       0.90      0.89      0.89        45\n",
            "\n",
            "\n",
            "=== 성능 비교 (Accuracy) ===\n",
            "                        Accuracy\n",
            "Linear Regression (회귀)  0.955556\n",
            "Logistic Regression     0.933333\n",
            "SVM                     1.000000\n",
            "Decision Tree           0.933333\n",
            "Random Forest           0.888889\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. 데이터 로드\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 2. 학습/테스트 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 3. 모델 정의\n",
        "models = {\n",
        "    \"Linear Regression (회귀)\": LinearRegression(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
        "    \"SVM\": SVC(kernel=\"linear\", C=1),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "}\n",
        "\n",
        "# 4. 학습 및 평가\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Linear Regression은 회귀값을 예측하므로 argmax 처리\n",
        "    if isinstance(model, LinearRegression):\n",
        "        y_pred_raw = model.predict(X_test)\n",
        "        y_pred = np.round(y_pred_raw).astype(int)\n",
        "        y_pred = np.clip(y_pred, 0, len(np.unique(y)) - 1)\n",
        "    else:\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[name] = acc\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Accuracy: {acc:.3f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "# 5. 결과 비교 테이블\n",
        "print(\"\\n=== 성능 비교 (Accuracy) ===\")\n",
        "df_results = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Accuracy\"])\n",
        "print(df_results)"
      ]
    }
  ]
}